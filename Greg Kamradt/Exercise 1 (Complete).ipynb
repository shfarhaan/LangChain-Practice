{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcfe991",
   "metadata": {
    "height": 146
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf1c6f6",
   "metadata": {
    "height": 163
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87ecd0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a883279",
   "metadata": {
    "height": 31
   },
   "source": [
    "# **Building A Language Model Application**\n",
    "\n",
    "### **LLMs: Get predictions from a language model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad9be0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d25b19",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377f7a2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1247546",
   "metadata": {
    "height": 78
   },
   "outputs": [],
   "source": [
    "text = \"What are 5 vacations for someone who likes to eat pasta?\"\n",
    "\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2962a46",
   "metadata": {
    "height": 31
   },
   "source": [
    "### Prompt Templates: Manage Prompts for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b14c6b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c49ed",
   "metadata": {
    "height": 95
   },
   "outputs": [],
   "source": [
    "prompt  = PromptTemplate(\n",
    "    input_variables = [\"food\"],\n",
    "    template = \"What are 5 vacations for someone who likes to eat {food}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e663e2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(prompt.format(food = \"Biriyani\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf3e45",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(llm(prompt.format(food = \"Biriyani\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e51a4c",
   "metadata": {
    "height": 31
   },
   "source": [
    "### **Chains: Combine LLMs and Prompts in multi-step workflows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e066480",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0be90",
   "metadata": {
    "height": 129
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template = \"What are 5 vacations for someone who likes to eat {food}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725a1dcb",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "chain = LLMChain(llm = llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee134f8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(chain.run(\"fruit\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e1390c",
   "metadata": {
    "height": 31
   },
   "source": [
    "### **Agents: Dynamically calls chains based on user input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d3cf8",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# pip install google-search-results\n",
    "\n",
    "!pip3 install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3503c40",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a594d",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Load the Model\n",
    "llm = OpenAI(temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0351ac6c",
   "metadata": {
    "height": 112
   },
   "outputs": [],
   "source": [
    "# Load in some tool to use\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"a5a22997beec6b42689ec395851beb34272d1b63b0815f08055ef2118859b03d\"\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff047e9e",
   "metadata": {
    "height": 78
   },
   "outputs": [],
   "source": [
    "# Finally, \n",
    "\n",
    "agent  = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5dc6d",
   "metadata": {
    "height": 44
   },
   "outputs": [],
   "source": [
    "agent.run(\"Who is the Sheldon Cooper? What is the name of their affiliation? Did he ever have any Cameo?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee008a1e",
   "metadata": {
    "height": 30
   },
   "source": [
    "### **Memory: Add state to chains and agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b56402e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d602e6a",
   "metadata": {
    "height": 61
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0)\n",
    "conversation = ConversationChain(llm=llm, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b651f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d060661e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "conversation.predict(input=\"I'm doing well! Just having a conversation with AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84ef9a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "conversation.predict(input = \"What was the first thing I said to you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e151c8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "conversation.predict(input = \"What is an alternative phrase for the first thing I said to you?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
